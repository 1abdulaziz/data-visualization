{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse-geocode Google location history\n",
    "\n",
    "In the previous notebook, we clustered the location history data to reduce the size of the data set. This reduced set was saved as 'location-history-clustered.csv'. Now we'll reverse-geocode it from lat/long to neighborhood, city, state, country. \n",
    "\n",
    "First, copy that csv file and rename the copy 'google-history-to-geocode.csv'. We'll use this file as our working file to do the reverse-geocoding. As Google limits your IP address to 2,500 requests per day, we might need to do the entire data set in multiple passes. Hence the working file.\n",
    "\n",
    "Sample request: https://maps.googleapis.com/maps/api/geocode/json?latlng=39.9058153,-86.054788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, time, requests, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the working file for geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pause = 0.1 #google limits you to 10 requests per second\n",
    "use_second_geocoder = False #only set True on your last pass, if multiple\n",
    "max_requests = 2500 #how many requests to make of google\n",
    "\n",
    "working_file = 'data/google-history-to-geocode.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,482 rows in dataset\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(working_file, encoding='utf-8')\n",
    "print('{:,} rows in dataset'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are more than 2,500 rows in the dataset, you need to run this notebook multiple times because Google limits you to 2,500 requests per day. Or fall back on the nominatim API, with `use_second_geocoder=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the data for geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>geocode_results</th>\n",
       "      <th>geocode_results_nominatum</th>\n",
       "      <th>latlng</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.310794</td>\n",
       "      <td>114.170237</td>\n",
       "      <td>2015-05-28 05:07:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kowloon</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>{\"place_id\": \"ChIJR9ZKTsAABDQRLKH_T7JIO_M\", \"f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.310794199999997,114.1702368</td>\n",
       "      <td>Yau Ma Tei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.798857</td>\n",
       "      <td>-122.279611</td>\n",
       "      <td>2016-02-13 16:10:43</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>{\"place_id\": \"ChIJT3t1CLmAj4AR48M7qyzExFk\", \"f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.7988567,-122.27961100000002</td>\n",
       "      <td>Downtown Oakland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.862522</td>\n",
       "      <td>-122.275418</td>\n",
       "      <td>2015-04-02 04:18:04</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>{\"place_id\": \"ChIJKTuMaoV-hYAR_BFYzZarN14\", \"f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.862522399999996,-122.2754184</td>\n",
       "      <td>South Berkeley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.009811</td>\n",
       "      <td>-159.338031</td>\n",
       "      <td>2015-01-19 10:46:41</td>\n",
       "      <td>Lihue</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>United States</td>\n",
       "      <td>{\"place_id\": \"ChIJkQWKeDMeB3wR2XhA2nIz4Ds\", \"f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.009811399999997,-159.3380307</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.860570</td>\n",
       "      <td>96.121303</td>\n",
       "      <td>2015-05-21 12:15:19</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Yangon Region</td>\n",
       "      <td>Myanmar (Burma)</td>\n",
       "      <td>{\"place_id\": \"ChIJ1daFCfqUwTARixlqX-_wCJ4\", \"f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.860569899999998,96.1213028</td>\n",
       "      <td>Mayangone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon             datetime      city          state  \\\n",
       "0  22.310794  114.170237  2015-05-28 05:07:24       NaN        Kowloon   \n",
       "1  37.798857 -122.279611  2016-02-13 16:10:43   Oakland     California   \n",
       "2  37.862522 -122.275418  2015-04-02 04:18:04  Berkeley     California   \n",
       "3  22.009811 -159.338031  2015-01-19 10:46:41     Lihue         Hawaii   \n",
       "4  16.860570   96.121303  2015-05-21 12:15:19    Yangon  Yangon Region   \n",
       "\n",
       "           country                                    geocode_results  \\\n",
       "0        Hong Kong  {\"place_id\": \"ChIJR9ZKTsAABDQRLKH_T7JIO_M\", \"f...   \n",
       "1    United States  {\"place_id\": \"ChIJT3t1CLmAj4AR48M7qyzExFk\", \"f...   \n",
       "2    United States  {\"place_id\": \"ChIJKTuMaoV-hYAR_BFYzZarN14\", \"f...   \n",
       "3    United States  {\"place_id\": \"ChIJkQWKeDMeB3wR2XhA2nIz4Ds\", \"f...   \n",
       "4  Myanmar (Burma)  {\"place_id\": \"ChIJ1daFCfqUwTARixlqX-_wCJ4\", \"f...   \n",
       "\n",
       "   geocode_results_nominatum                           latlng  \\\n",
       "0                        NaN   22.310794199999997,114.1702368   \n",
       "1                        NaN   37.7988567,-122.27961100000002   \n",
       "2                        NaN  37.862522399999996,-122.2754184   \n",
       "3                        NaN  22.009811399999997,-159.3380307   \n",
       "4                        NaN    16.860569899999998,96.1213028   \n",
       "\n",
       "       neighborhood  \n",
       "0        Yau Ma Tei  \n",
       "1  Downtown Oakland  \n",
       "2    South Berkeley  \n",
       "3               NaN  \n",
       "4         Mayangone  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create city, state, country columns only if they don't already exist\n",
    "new_cols = ['city', 'state', 'country', 'geocode_results', 'geocode_results_nominatum']\n",
    "for col in new_cols:\n",
    "    if not col in df.columns:\n",
    "        df[col] = None\n",
    "        \n",
    "# drop the locations and timestamp_ms columns if they are still here\n",
    "cols_to_remove = ['locations', 'timestamp_ms']\n",
    "for col in cols_to_remove:\n",
    "    if col in df.columns:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put latlng in the format google likes so it's easy to call their api\n",
    "df['latlng'] = df.apply(lambda row: '{},{}'.format(row['lat'], row['lon']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if this isn't the first pass through the reverse-geocoder, we will already have some saved results\n",
    "# they were saved as json strings, so load them as python dicts now to work with them\n",
    "f = lambda x: json.loads(x) if isinstance(x, str) else x\n",
    "df['geocode_results'] = df['geocode_results'].map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993 out of 3,482 rows lack reverse-geocode results\n",
      "We will attempt to reverse-geocode up to 2,500 rows\n"
     ]
    }
   ],
   "source": [
    "ungeocoded_rows = df[pd.isnull(df['geocode_results']) & pd.isnull(df['geocode_results_nominatum'])]\n",
    "print('{:,} out of {:,} rows lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))\n",
    "print('We will attempt to reverse-geocode up to {:,} rows'.format(max_requests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now reverse-geocode the google location history to city/country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pass the Google API latlng data to reverse geocode it\n",
    "count_requests = 0\n",
    "def reverse_geocode(row):\n",
    "    global count_requests\n",
    "    if row.name % 100 == 0: print(row.name, end=' ')\n",
    "    \n",
    "    # first check if either geocode result column already has data\n",
    "    if pd.notnull(row['geocode_results']):\n",
    "        return row['geocode_results']\n",
    "    elif pd.notnull(row['geocode_results_nominatum']):\n",
    "        return None\n",
    "    elif count_requests < max_requests:\n",
    "        # this row has not yet been reverse geocoded and we have not yet made the max # of requests\n",
    "        time.sleep(pause)\n",
    "        url = 'https://maps.googleapis.com/maps/api/geocode/json?latlng={}'\n",
    "        request = url.format(row['latlng'])\n",
    "        response = requests.get(request)\n",
    "        count_requests += 1\n",
    "        data = response.json()\n",
    "        if len(data['results']) > 0:\n",
    "            return data['results'][0] #if we got results, return the first result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 "
     ]
    }
   ],
   "source": [
    "df['geocode_results'] = df.apply(reverse_geocode, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 out of 3,482 rows lack reverse-geocode results\n"
     ]
    }
   ],
   "source": [
    "ungeocoded_rows = df[pd.isnull(df['geocode_results']) & pd.isnull(df['geocode_results_nominatum'])]\n",
    "print('{:,} out of {:,} rows lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now parse city, state, country from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_neighborhood(row):\n",
    "    if pd.notnull(row['geocode_results']):\n",
    "        if 'address_components' in row['geocode_results']:\n",
    "            for component in row['geocode_results']['address_components']:\n",
    "                if 'neighborhood' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'sublocality_level_1' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'sublocality_level_2' in component['types']:\n",
    "                    return component['long_name']                \n",
    "                \n",
    "# to find city, return the finest-grain address component \n",
    "# google returns these components in order from finest to coarsest grained\n",
    "def get_city(row):\n",
    "    if pd.notnull(row['geocode_results']):\n",
    "        if 'address_components' in row['geocode_results']:\n",
    "            for component in row['geocode_results']['address_components']:\n",
    "                if 'locality' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'postal_town' in component['types']:\n",
    "                    return component['long_name']              \n",
    "                elif 'administrative_area_level_5' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_4' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_3' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_2' in component['types']:\n",
    "                    return component['long_name']\n",
    "\n",
    "# to find state, you want the lowest-level admin area available\n",
    "# but, google returns admin areas listed from highest-level to lowest\n",
    "# so you can't just return as soon as you find the first match\n",
    "# this is is opposite of the previous, because this time we want the coarsest-grain match\n",
    "# otherwise we end up with counties and so forth instead of states\n",
    "def get_state(row):\n",
    "    if pd.notnull(row['geocode_results']):\n",
    "        state = None\n",
    "        if 'address_components' in row['geocode_results']:\n",
    "            for component in row['geocode_results']['address_components']:\n",
    "                if 'administrative_area_level_1' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'administrative_area_level_2' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'administrative_area_level_3' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'locality' in component['types']:\n",
    "                    state = component['long_name']\n",
    "        return state\n",
    "\n",
    "def get_country(row):\n",
    "    if pd.notnull(row['geocode_results']):\n",
    "        if 'address_components' in row['geocode_results']:\n",
    "            for component in row['geocode_results']['address_components']:\n",
    "                if 'country' in component['types']:\n",
    "                    return component['long_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now apply our functions to extract neighborhood, city, state, country\n",
    "df['neighborhood'] = df.apply(get_neighborhood, axis=1)\n",
    "df['city'] = df.apply(get_city, axis=1)\n",
    "df['state'] = df.apply(get_state, axis=1)\n",
    "df['country'] = df.apply(get_country, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 out of 3,482 rows lack city, state, and country\n",
      "14 out of 3,482 rows lack reverse-geocode results\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isnull(df['city']) & pd.isnull(df['state']) & pd.isnull(df['country'])\n",
    "print('{:,} out of {:,} rows lack city, state, and country'.format(len(df[mask]), len(df)))\n",
    "ungeocoded_rows = df[pd.isnull(df['geocode_results']) & pd.isnull(df['geocode_results_nominatum'])]\n",
    "print('{:,} out of {:,} rows lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If use_second_geocoder is True, use OSM Nominatum API to reverse-geocode any remaining missing rows\n",
    "\n",
    "Only do this on the final pass. This is useful for places like Kosovo that Google does not return results for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pass latlng data to osm nominatum to reverse geocode it\n",
    "def reverse_geocode_nominatum(label, lat, lon):\n",
    "    print(label, end=' ')\n",
    "    time.sleep(pause)\n",
    "    url = 'https://nominatim.openstreetmap.org/reverse?format=json&lat={}&lon={}&zoom=18&addressdetails=1'\n",
    "    request = url.format(lat, lon)\n",
    "    response = requests.get(request)\n",
    "    data = response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_nominatum_data(data):\n",
    "    country = None\n",
    "    state = None\n",
    "    city = None\n",
    "    if isinstance(data, dict):\n",
    "        if 'address' in data:\n",
    "            if 'country' in data['address']:\n",
    "                country = data['address']['country']\n",
    "\n",
    "            #state\n",
    "            if 'region' in data['address']:\n",
    "                state = data['address']['region']\n",
    "            if 'state' in data['address']:\n",
    "                state = data['address']['state']\n",
    "\n",
    "            #city\n",
    "            if 'county' in data['address']:\n",
    "                county = data['address']['county']\n",
    "            if 'village' in data['address']:\n",
    "                city = data['address']['village']\n",
    "            if 'city' in data['address']:\n",
    "                city = data['address']['city']\n",
    "    return city, state, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228 314 710 1041 1144 1362 1490 1664 1717 2077 2146 3032 3154 3401 "
     ]
    }
   ],
   "source": [
    "if use_second_geocoder:\n",
    "    df['geocode_results_nominatum'] = None\n",
    "    for label, row in df.iterrows():\n",
    "        if pd.isnull(row['geocode_results']):\n",
    "            result = reverse_geocode_nominatum(label, row['lat'], row['lon'])\n",
    "            city, state, country = parse_nominatum_data(result)\n",
    "            df.loc[label, 'city'] = city\n",
    "            df.loc[label, 'state'] = state\n",
    "            df.loc[label, 'country'] = country\n",
    "            df.loc[label, 'geocode_results_nominatum'] = json.dumps(result, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 3,482 rows lack city, state, and country\n",
      "0 out of 3,482 rows lack reverse-geocode results\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isnull(df['city']) & pd.isnull(df['state']) & pd.isnull(df['country'])\n",
    "print('{:,} out of {:,} rows lack city, state, and country'.format(len(df[mask]), len(df)))\n",
    "ungeocoded_rows = df[pd.isnull(df['geocode_results']) & pd.isnull(df['geocode_results_nominatum'])]\n",
    "print('{:,} out of {:,} rows lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done: Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dump the geocode_results to json string before saving so it saves nicely as text\n",
    "f = lambda x: x if isinstance(x, str) else json.dumps(x, ensure_ascii=False)\n",
    "df['geocode_results'] = df['geocode_results'].map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the entire data set to the working file\n",
    "df.to_csv(working_file, encoding='utf-8', index=False)\n",
    "\n",
    "# save the useful columns to a final output file\n",
    "cols_to_retain = ['datetime', 'neighborhood', 'city', 'state', 'country', 'lat', 'lon']\n",
    "df[cols_to_retain].to_csv('data/google-location-history.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
