{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse-geocode Google location history\n",
    "\n",
    "In the previous notebook, we clustered the location history data to reduce the size of the data set. This reduced set was saved as 'location-history-clustered.csv'. Now we'll reverse-geocode it from lat/long to neighborhood, city, state, country. \n",
    "\n",
    "First, this script copies that csv file and renames the copy 'google-history-to-geocode.csv'. It uses this file as our working file to do the reverse-geocoding. As Google limits your IP address to 2,500 requests per day, we might need to do the entire data set in multiple passes. Hence the working file.\n",
    "\n",
    "Sample request: https://maps.googleapis.com/maps/api/geocode/json?latlng=39.9058153,-86.054788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, time, requests, json, os.path, logging as lg, datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pause = 0.1 #google limits you to 10 requests per second\n",
    "use_second_geocoder = False #only set True on your last pass, if multiple\n",
    "max_google_requests = 2500 #how many requests to make of google\n",
    "google_requests_count = 0\n",
    "final_output_filename = 'data/google-location-history.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure local caching\n",
    "geocode_cache_filename = 'data/reverse_geocode_cache.js'\n",
    "cache_save_frequency = 10\n",
    "requests_count = 0\n",
    "geocode_cache = json.load(open(geocode_cache_filename)) if os.path.isfile(geocode_cache_filename) else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a logger to capture progress\n",
    "log = lg.getLogger('reverse_geocoder')\n",
    "if not getattr(log, 'handler_set', None):\n",
    "    todays_date = dt.datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    log_filename = 'logs/reverse_geocoder_{}.log'.format(todays_date)\n",
    "    handler = lg.FileHandler(log_filename, encoding='utf-8')\n",
    "    formatter = lg.Formatter('%(asctime)s %(levelname)s %(name)s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    log.addHandler(handler)\n",
    "    log.setLevel(lg.INFO)\n",
    "    log.handler_set = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up the working file (see note at top of notebook)\n",
    "working_filename = 'data/google-history-to-geocode.csv'\n",
    "if not os.path.isfile(working_filename):\n",
    "    df_temp = pd.read_csv('data/location-history-clustered.csv', encoding='utf-8')\n",
    "    df_temp.to_csv(working_filename, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saves the dict cache to disk as json\n",
    "def save_cache_to_disk(cache, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as cache_file:\n",
    "        cache_file.write(json.dumps(cache))\n",
    "    log.info('saved {:,} cached items to {}'.format(len(cache.keys()), filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a http request\n",
    "def make_request(url):\n",
    "    log.info('requesting {}'.format(url))\n",
    "    return requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse neighborhood data from a google reverse-geocode result\n",
    "def get_neighborhood_google(result):\n",
    "    if pd.notnull(result):\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'neighborhood' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'sublocality_level_1' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'sublocality_level_2' in component['types']:\n",
    "                    return component['long_name']                \n",
    "\n",
    "# parse city data from a google reverse-geocode result\n",
    "# to find city, return the finest-grain address component \n",
    "# google returns these components in order from finest to coarsest grained\n",
    "def get_city_google(result):\n",
    "    if pd.notnull(result):\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'locality' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'postal_town' in component['types']:\n",
    "                    return component['long_name']              \n",
    "                elif 'administrative_area_level_5' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_4' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_3' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_2' in component['types']:\n",
    "                    return component['long_name']\n",
    "\n",
    "# parse state data from a google reverse-geocode result                \n",
    "# to find state, you want the lowest-level admin area available\n",
    "# but, google returns admin areas listed from highest-level to lowest\n",
    "# so you can't just return as soon as you find the first match\n",
    "# this is is opposite of the previous, because this time we want the coarsest-grain match\n",
    "# otherwise we end up with counties and so forth instead of states\n",
    "def get_state_google(result):\n",
    "    if pd.notnull(result):\n",
    "        state = None\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'administrative_area_level_1' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'administrative_area_level_2' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'administrative_area_level_3' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'locality' in component['types']:\n",
    "                    state = component['long_name']\n",
    "        return state\n",
    "\n",
    "# parse country data from a google reverse-geocode result\n",
    "def get_country_google(result):\n",
    "    if pd.notnull(result):\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'country' in component['types']:\n",
    "                    return component['long_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse city, state, country data from a nominatim reverse-geocode result\n",
    "def parse_nominatim_data(data):\n",
    "    country = None\n",
    "    state = None\n",
    "    city = None\n",
    "    if isinstance(data, dict):\n",
    "        if 'address' in data:\n",
    "            if 'country' in data['address']:\n",
    "                country = data['address']['country']\n",
    "\n",
    "            #state\n",
    "            if 'region' in data['address']:\n",
    "                state = data['address']['region']\n",
    "            if 'state' in data['address']:\n",
    "                state = data['address']['state']\n",
    "\n",
    "            #city\n",
    "            if 'county' in data['address']:\n",
    "                county = data['address']['county']\n",
    "            if 'village' in data['address']:\n",
    "                city = data['address']['village']\n",
    "            if 'city' in data['address']:\n",
    "                city = data['address']['city']\n",
    "    return city, state, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pass latlng data to osm nominatim to reverse geocode it\n",
    "def reverse_geocode_nominatim(latlng):\n",
    "\n",
    "    time.sleep(pause)\n",
    "    url = 'https://nominatim.openstreetmap.org/reverse?format=json&lat={}&lon={}&zoom=18&addressdetails=1'\n",
    "    data = make_request(url.format(latlng.split(',')[0], latlng.split(',')[1]))\n",
    "\n",
    "    place = {}\n",
    "    place['neighborhood'] = None\n",
    "    place['city'], place['state'], place['country'] = parse_nominatim_data(data)\n",
    "    return place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pass the Google API latlng data to reverse geocode it\n",
    "def reverse_geocode_google(latlng):\n",
    "    \n",
    "    global google_requests_count\n",
    "    \n",
    "    if google_requests_count < max_google_requests:\n",
    "        # we have not yet made the max # of requests\n",
    "        time.sleep(pause)\n",
    "        google_requests_count += 1\n",
    "        url = 'https://maps.googleapis.com/maps/api/geocode/json?latlng={}'\n",
    "        data = make_request(url.format(latlng))\n",
    "        if len(data['results']) > 0:\n",
    "            result = data['results'][0]\n",
    "            \n",
    "            place = {}\n",
    "            place['neighborhood'] = get_neighborhood_google(result)\n",
    "            place['city'] = get_city_google(result)\n",
    "            place['state'] = get_state_google(result)\n",
    "            place['country'] = get_country_google(result)\n",
    "            return place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_geocode(latlng, reverse_geocode_function=reverse_geocode_google, use_cache=True):\n",
    "    \n",
    "    global geocode_cache, requests_count\n",
    "    \n",
    "    if use_cache and latlng in geocode_cache and pd.notnull(geocode_cache[latlng]):\n",
    "        log.info('retrieving results from cache for lat-long \"{}\"'.format(latlng))\n",
    "        return geocode_cache[latlng]\n",
    "    else:\n",
    "        place = reverse_geocode_function(latlng)\n",
    "        geocode_cache[latlng] = place\n",
    "        log.info('stored place details in cache for lat-long \"{}\"'.format(latlng))\n",
    "        \n",
    "        requests_count += 1\n",
    "        if requests_count % cache_save_frequency == 0: \n",
    "            save_cache_to_disk(geocode_cache, geocode_cache_filename)\n",
    "            \n",
    "        return place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_place_by_latlng(latlng, component):\n",
    "    try:\n",
    "        return place_dict[latlng][component]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the data for geocoding\n",
    "\n",
    "If there are more than 2,500 rows in the dataset, you need to run this notebook multiple times because Google limits you to 2,500 requests per day. Or fall back on the nominatim API, with `use_second_geocoder=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,482 rows in dataset\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(working_filename, encoding='utf-8')\n",
    "print('{:,} rows in dataset'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.310794</td>\n",
       "      <td>114.170237</td>\n",
       "      <td>2015-05-28 05:07:24</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.798857</td>\n",
       "      <td>-122.279611</td>\n",
       "      <td>2016-02-13 16:10:43</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.862522</td>\n",
       "      <td>-122.275418</td>\n",
       "      <td>2015-04-02 04:18:04</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.009811</td>\n",
       "      <td>-159.338031</td>\n",
       "      <td>2015-01-19 10:46:41</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.860570</td>\n",
       "      <td>96.121303</td>\n",
       "      <td>2015-05-21 12:15:19</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon             datetime  city state country neighborhood\n",
       "0  22.310794  114.170237  2015-05-28 05:07:24  None  None    None         None\n",
       "1  37.798857 -122.279611  2016-02-13 16:10:43  None  None    None         None\n",
       "2  37.862522 -122.275418  2015-04-02 04:18:04  None  None    None         None\n",
       "3  22.009811 -159.338031  2015-01-19 10:46:41  None  None    None         None\n",
       "4  16.860570   96.121303  2015-05-21 12:15:19  None  None    None         None"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create city, state, country columns only if they don't already exist\n",
    "new_cols = ['city', 'state', 'country', 'neighborhood']\n",
    "for col in new_cols:\n",
    "    if not col in df.columns:\n",
    "        df[col] = None\n",
    "        \n",
    "# drop the locations and timestamp_ms columns if they are still here\n",
    "cols_to_remove = ['locations', 'timestamp_ms']\n",
    "for col in cols_to_remove:\n",
    "    if col in df.columns:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put latlng in the format google likes so it's easy to call their api\n",
    "# and round to 7 decimal places so our cache's keys are consistent\n",
    "# (so you don't get weird float precision artifacts like 114.1702368000000001)\n",
    "df['latlng'] = df.apply(lambda row: '{:.7f},{:.7f}'.format(row['lat'], row['lon']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,482 out of 3,482 rows lack reverse-geocode results\n",
      "We will attempt to reverse-geocode up to 2,500 rows with Google\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isnull(df['country']) & pd.isnull(df['state']) & pd.isnull(df['city']) & pd.isnull(df['neighborhood'])\n",
    "ungeocoded_rows = df[mask]\n",
    "print('{:,} out of {:,} rows lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))\n",
    "print('We will attempt to reverse-geocode up to {:,} rows with Google'.format(max_google_requests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now reverse-geocode the location history with the Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_latlngs = df['latlng'].dropna().sort_values().unique()\n",
    "place_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for latlng in unique_latlngs:\n",
    "    place_dict[latlng] = reverse_geocode(latlng, reverse_geocode_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for component in ['country', 'state', 'city', 'neighborhood']:\n",
    "    df[component] = df['latlng'].apply(get_place_by_latlng, args=(component,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 3,482 rows still lack reverse-geocode results\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isnull(df['country']) & pd.isnull(df['state']) & pd.isnull(df['city']) & pd.isnull(df['neighborhood'])\n",
    "ungeocoded_rows = df[mask]\n",
    "print('{:,} out of {:,} rows still lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next reverse-geocode missing rows with the Nominatim API\n",
    "\n",
    "If use_second_geocoder is True, use OSM Nominatum API to reverse-geocode any remaining missing rows. Only do this on the final pass. This is useful for places like Kosovo that Google does not return results for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if use_second_geocoder:\n",
    "    unique_latlngs = ungeocoded_rows['latlng'].dropna().sort_values().unique()\n",
    "    for latlng in unique_latlngs:\n",
    "        place_dict[latlng] = reverse_geocode(latlng, reverse_geocode_nominatim)\n",
    "    for component in ['country', 'state', 'city', 'neighborhood']:\n",
    "        df[component] = df['latlng'].apply(get_place_by_latlng, args=(component,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 3,482 rows still lack reverse-geocode results\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isnull(df['country']) & pd.isnull(df['state']) & pd.isnull(df['city']) & pd.isnull(df['neighborhood'])\n",
    "ungeocoded_rows = df[mask]\n",
    "print('{:,} out of {:,} rows still lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done: Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>latlng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>-37.668605</td>\n",
       "      <td>144.850033</td>\n",
       "      <td>2016-06-08 13:40:05</td>\n",
       "      <td>Melbourne Airport</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Australia</td>\n",
       "      <td>None</td>\n",
       "      <td>-37.6686055,144.8500327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>37.866393</td>\n",
       "      <td>-122.277176</td>\n",
       "      <td>2014-08-17 14:23:48</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>Central Berkeley</td>\n",
       "      <td>37.8663925,-122.2771756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>45.545606</td>\n",
       "      <td>-122.676001</td>\n",
       "      <td>2015-07-28 23:08:20</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>United States</td>\n",
       "      <td>North Portland</td>\n",
       "      <td>45.5456062,-122.6760010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>40.289631</td>\n",
       "      <td>-8.482598</td>\n",
       "      <td>2014-05-17 06:03:15</td>\n",
       "      <td>None</td>\n",
       "      <td>Coimbra</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>None</td>\n",
       "      <td>40.2896306,-8.4825983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>41.289419</td>\n",
       "      <td>2.070906</td>\n",
       "      <td>2014-05-18 16:07:50</td>\n",
       "      <td>El Prat de Llobregat</td>\n",
       "      <td>Catalunya</td>\n",
       "      <td>Spain</td>\n",
       "      <td>None</td>\n",
       "      <td>41.2894187,2.0709061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat         lon             datetime                  city  \\\n",
       "3477 -37.668605  144.850033  2016-06-08 13:40:05     Melbourne Airport   \n",
       "3478  37.866393 -122.277176  2014-08-17 14:23:48              Berkeley   \n",
       "3479  45.545606 -122.676001  2015-07-28 23:08:20              Portland   \n",
       "3480  40.289631   -8.482598  2014-05-17 06:03:15                  None   \n",
       "3481  41.289419    2.070906  2014-05-18 16:07:50  El Prat de Llobregat   \n",
       "\n",
       "           state        country      neighborhood                   latlng  \n",
       "3477    Victoria      Australia              None  -37.6686055,144.8500327  \n",
       "3478  California  United States  Central Berkeley  37.8663925,-122.2771756  \n",
       "3479      Oregon  United States    North Portland  45.5456062,-122.6760010  \n",
       "3480     Coimbra       Portugal              None    40.2896306,-8.4825983  \n",
       "3481   Catalunya          Spain              None     41.2894187,2.0709061  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save cache to disk\n",
    "save_cache_to_disk(geocode_cache, geocode_cache_filename)\n",
    "\n",
    "# save the entire data set to the working file\n",
    "df.to_csv(working_filename, encoding='utf-8', index=False)\n",
    "\n",
    "# save the useful columns to a final output file\n",
    "cols_to_retain = ['datetime', 'neighborhood', 'city', 'state', 'country', 'lat', 'lon']\n",
    "df[cols_to_retain].to_csv(final_output_filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
